{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Clustering Exploratory Analysis\n",
    "\n",
    "This notebook demonstrates the exploratory data analysis and clustering process for stock price data.\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=2.0.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.24.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 2)) (2.3.5)\n",
      "Requirement already satisfied: yfinance>=0.2.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 4)) (2.0.46)\n",
      "Requirement already satisfied: psycopg2-binary>=2.9.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 5)) (2.9.11)\n",
      "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 6)) (1.8.0)\n",
      "Requirement already satisfied: tslearn>=0.6.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 8)) (3.10.8)\n",
      "Requirement already satisfied: seaborn>=0.12.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: plotly>=5.15.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 10)) (6.5.2)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 11)) (4.67.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 12)) (1.17.0)\n",
      "Requirement already satisfied: pyarrow>=10.0.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from -r ../requirements.txt (line 13)) (23.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/src/clustering/venv/lib/python3.12/site-packages (from pandas>=2.0.0->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: requests>=2.31 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (0.0.12)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (4.5.1)\n",
      "Requirement already satisfied: pytz>=2022.5 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (3.19.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (4.14.3)\n",
      "Requirement already satisfied: curl_cffi<0.14,>=0.7 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (0.13.0)\n",
      "Requirement already satisfied: protobuf>=3.19.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (6.33.5)\n",
      "Requirement already satisfied: websockets>=13.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from yfinance>=0.2.0->-r ../requirements.txt (line 3)) (16.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from sqlalchemy>=2.0.0->-r ../requirements.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from sqlalchemy>=2.0.0->-r ../requirements.txt (line 4)) (4.15.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from scikit-learn>=1.3.0->-r ../requirements.txt (line 6)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from scikit-learn>=1.3.0->-r ../requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: numba>=0.58.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from tslearn>=0.6.0->-r ../requirements.txt (line 7)) (0.63.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/src/clustering/venv/lib/python3.12/site-packages (from matplotlib>=3.7.0->-r ../requirements.txt (line 8)) (3.3.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from plotly>=5.15.0->-r ../requirements.txt (line 10)) (2.16.0)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2.8.3)\n",
      "Requirement already satisfied: cffi>=1.12.0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2024.2.2 in /usr/src/clustering/venv/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2026.1.4)\n",
      "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /usr/src/clustering/venv/lib/python3.12/site-packages (from numba>=0.58.1->tslearn>=0.6.0->-r ../requirements.txt (line 7)) (0.46.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/src/clustering/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r ../requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/src/clustering/venv/lib/python3.12/site-packages (from requests>=2.31->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/src/clustering/venv/lib/python3.12/site-packages (from requests>=2.31->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/src/clustering/venv/lib/python3.12/site-packages (from requests>=2.31->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (2.6.3)\n",
      "Requirement already satisfied: pycparser in /usr/src/clustering/venv/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance>=0.2.0->-r ../requirements.txt (line 3)) (3.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install -r ../requirements.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Install required packages if needed\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path().absolute().parent / \"src\"))\n",
    "\n",
    "from src.data_fetcher import DataFetcher\n",
    "from src.feature_extractor import FeatureExtractor\n",
    "from src.clustering import StockClustering\n",
    "from src.visualizer import ClusterVisualizer\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Fetching Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data fetcher\n",
    "data_fetcher = DataFetcher(cache_dir=\"../data/raw\")\n",
    "\n",
    "# Test with a small sample of symbols\n",
    "test_symbols = ['AAPL', 'MSFT', 'GOOGL', 'TSLA', 'AMZN']\n",
    "\n",
    "print(\"Fetching data for test symbols...\")\n",
    "stock_data_dict = data_fetcher.fetch_multiple_stocks_data(\n",
    "    test_symbols, \n",
    "    period=\"2y\",  # 2 years for faster testing\n",
    "    validate_symbols=True\n",
    ")\n",
    "\n",
    "print(f\"Successfully fetched data for {len(stock_data_dict)} symbols\")\n",
    "print(f\"Symbols: {list(stock_data_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data\n",
    "if stock_data_dict:\n",
    "    combined_data = data_fetcher.combine_all_data(stock_data_dict)\n",
    "    print(f\"Combined data shape: {combined_data.shape}\")\n",
    "    print(f\"Columns: {list(combined_data.columns)}\")\n",
    "    print(f\"Date range: {combined_data['date'].min()} to {combined_data['date'].max()}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    display(combined_data.head())\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\nBasic statistics:\")\n",
    "    display(combined_data.describe())\n",
    "else:\n",
    "    print(\"No data fetched to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict:\n",
    "    # Initialize feature extractor\n",
    "    feature_extractor = FeatureExtractor()\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"Extracting features...\")\n",
    "    features_with_data = feature_extractor.extract_features_for_clustering(combined_data)\n",
    "    \n",
    "    print(f\"Features extracted. Shape: {features_with_data.shape}\")\n",
    "    print(f\"Feature columns: {[col for col in features_with_data.columns if col not in ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']]}\")\n",
    "    \n",
    "    # Display sample of features\n",
    "    print(\"\\nSample of extracted features:\")\n",
    "    feature_cols = [col for col in features_with_data.columns if col not in ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    display(features_with_data[['symbol', 'date'] + feature_cols[:10]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fluctuation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict:\n",
    "    # Analyze fluctuation patterns (30-70% ranges)\n",
    "    fluctuation_stats = feature_extractor.count_fluctuation_cycles(\n",
    "        combined_data, \n",
    "        min_pct=30, \n",
    "        max_pct=70\n",
    "    )\n",
    "    \n",
    "    print(\"Fluctuation Analysis (30-70% ranges):\")\n",
    "    for symbol, stats in fluctuation_stats.items():\n",
    "        print(f\"\\n{symbol}:\")\n",
    "        print(f\"  Fluctuation count: {stats['fluctuation_count']}\")\n",
    "        print(f\"  Average period: {stats['avg_fluctuation_period']:.1f} days\")\n",
    "        print(f\"  Frequency: {stats['fluctuation_frequency']:.2f} per year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Matrix Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict:\n",
    "    # Create feature matrix for clustering\n",
    "    feature_matrix = feature_extractor.create_feature_matrix(\n",
    "        features_with_data, \n",
    "        features_per_symbol=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "    print(f\"Feature matrix columns: {list(feature_matrix.columns)}\")\n",
    "    \n",
    "    # Prepare features for clustering\n",
    "    clustering_features, scaler = feature_extractor.prepare_features_for_clustering(\n",
    "        feature_matrix\n",
    "    )\n",
    "    \n",
    "    print(f\"Clustering features shape: {clustering_features.shape}\")\n",
    "    \n",
    "    # Display feature matrix\n",
    "    display(feature_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict and len(feature_matrix) > 2:\n",
    "    # Initialize clustering analyzer\n",
    "    clustering_analyzer = StockClustering(max_clusters=5)  # Smaller for testing\n",
    "    \n",
    "    # Find optimal number of clusters\n",
    "    print(\"Finding optimal number of clusters...\")\n",
    "    cluster_results = clustering_analyzer.find_optimal_clusters(\n",
    "        clustering_features, \n",
    "        cluster_range=range(2, min(6, len(feature_matrix)))  # Test 2-5 clusters\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCluster evaluation results:\")\n",
    "    for n_clusters, metrics in cluster_results.items():\n",
    "        print(f\"{n_clusters} clusters: Silhouette={metrics['silhouette_score']:.3f}, \"\n",
    "              f\"Calinski-Harabasz={metrics['calinski_harabasz_score']:.1f}, \"\n",
    "              f\"Davies-Bouldin={metrics['davies_bouldin_score']:.3f}\")\n",
    "    \n",
    "    # Select best and perform clustering\n",
    "    best_n_clusters = clustering_analyzer.select_best_n_clusters(cluster_results)\n",
    "    print(f\"\\nSelected optimal clusters: {best_n_clusters}\")\n",
    "    \n",
    "    # Perform clustering\n",
    "    cluster_labels = clustering_analyzer.perform_clustering(\n",
    "        clustering_features,\n",
    "        n_clusters=best_n_clusters,\n",
    "        auto_optimize=False\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nClustering completed. Labels: {cluster_labels}\")\n",
    "    \n",
    "    # Analyze clusters\n",
    "    cluster_analysis = clustering_analyzer.analyze_clusters(feature_matrix, cluster_labels)\n",
    "    \n",
    "    print(\"\\nCluster analysis:\")\n",
    "    for cluster_id, stats in cluster_analysis.items():\n",
    "        print(f\"\\nCluster {cluster_id}:\")\n",
    "        print(f\"  Size: {stats['size']} stocks\")\n",
    "        print(f\"  Symbols: {', '.join(stats.get('symbols', []))}\")\n",
    "        print(f\"  Avg volatility: {stats.get('volatility_252d_mean', 0):.3f}\")\n",
    "        print(f\"  Avg return: {stats.get('return_mean', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict and len(feature_matrix) > 2:\n",
    "    # Initialize visualizer\n",
    "    visualizer = ClusterVisualizer(output_dir=\"../reports\")\n",
    "    \n",
    "    # Get cluster assignments\n",
    "    cluster_assignments = clustering_analyzer.get_cluster_assignments(feature_matrix)\n",
    "    \n",
    "    # Reduce dimensions for visualization\n",
    "    features_2d, _ = clustering_analyzer.reduce_dimensions(\n",
    "        clustering_features, method='pca', n_components=2\n",
    "    )\n",
    "    \n",
    "    # Generate descriptive labels\n",
    "    descriptive_labels = clustering_analyzer.generate_cluster_labels(cluster_analysis)\n",
    "    print(\"\\nDescriptive cluster labels:\")\n",
    "    for cluster_id, label in descriptive_labels.items():\n",
    "        print(f\"  Cluster {cluster_id}: {label}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    plots_created = visualizer.create_comprehensive_report(\n",
    "        features_2d=features_2d,\n",
    "        cluster_labels=cluster_labels,\n",
    "        cluster_assignments=cluster_assignments,\n",
    "        cluster_analysis=cluster_analysis,\n",
    "        clustering_metrics=clustering_analyzer.evaluate_clustering_quality(clustering_features, cluster_labels),\n",
    "        stock_data=combined_data,\n",
    "        method='PCA'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nVisualizations created:\")\n",
    "    for plot_name, plot_path in plots_created.items():\n",
    "        print(f\"  {plot_name}: {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stock_data_dict:\n",
    "    print(\"=== STOCK CLUSTERING ANALYSIS SUMMARY ===\")\n",
    "    print(f\"\\nData Overview:\")\n",
    "    print(f\"  - Symbols analyzed: {len(stock_data_dict)}\")\n",
    "    print(f\"  - Data points per symbol: {len(combined_data) // len(stock_data_dict)}\")\n",
    "    print(f\"  - Date range: {combined_data['date'].min().strftime('%Y-%m-%d')} to {combined_data['date'].max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    print(f\"\\nFeature Engineering:\")\n",
    "    print(f\"  - Total features extracted: {len([col for col in features_with_data.columns if col not in ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume']])}\")\n",
    "    print(f\"  - Feature matrix shape: {feature_matrix.shape}\")\n",
    "    \n",
    "    if len(feature_matrix) > 2:\n",
    "        print(f\"\\nClustering Results:\")\n",
    "        print(f\"  - Optimal clusters found: {best_n_clusters}\")\n",
    "        print(f\"  - Clustering quality metrics calculated\")\n",
    "        \n",
    "        for cluster_id, stats in cluster_analysis.items():\n",
    "            label = descriptive_labels.get(cluster_id, f\"Cluster {cluster_id}\")\n",
    "            print(f\"  - {label}: {stats['size']} stocks\")\n",
    "    \n",
    "    print(f\"\\nFluctuation Analysis (30-70% ranges):\")\n",
    "    for symbol, stats in fluctuation_stats.items():\n",
    "        if stats['fluctuation_count'] > 0:\n",
    "            print(f\"  - {symbol}: {stats['fluctuation_count']} cycles, avg period {stats['avg_fluctuation_period']:.0f} days\")\n",
    "        else:\n",
    "            print(f\"  - {symbol}: No significant fluctuations detected\")\n",
    "    \n",
    "    print(f\"\\nOutputs Generated:\")\n",
    "    if 'plots_created' in locals():\n",
    "        for plot_name, plot_path in plots_created.items():\n",
    "            print(f\"  - {plot_name}: {plot_path}\")\n",
    "else:\n",
    "    print(\"No data available for analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
